{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading env variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#initiate load_env variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import other dependencies\n",
    "from langsmith import utils\n",
    "utils.tracing_is_enabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load llm model\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model='gpt-4o-mini', temperature= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the content\n",
    "\n",
    "def llm_ops_content():\n",
    "    with open('llmops_sample.txt', 'r') as file:\n",
    "        content = file.read()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# Define the prompt using ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a helpful assistant. Here is the context for you to assist me: {context}\\nRespond to the question based on the context\"),\n",
    "    (\"user\",\"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the prompt and model into a chain\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLOps (Machine Learning Operations) and DevOps (Development Operations) share some foundational principles, but they differ significantly in their focus and practices due to the unique challenges associated with machine learning systems. Here are the key differences:\n",
      "\n",
      "1. **Focus**:\n",
      "   - **DevOps**: Primarily focuses on the software development lifecycle, emphasizing collaboration between development and operations teams to streamline software delivery and improve deployment frequency.\n",
      "   - **MLOps**: Specifically addresses the operationalization of machine learning models, focusing on the entire lifecycle of machine learning systems, including data management, model training, deployment, monitoring, and continuous improvement.\n",
      "\n",
      "2. **Complexity of Artifacts**:\n",
      "   - **DevOps**: Deals with code, applications, and infrastructure. The artifacts are generally well-defined and version-controlled.\n",
      "   - **MLOps**: Involves a more complex set of artifacts, including datasets, models, training scripts, and evaluation metrics. It also requires managing the interplay between data and models, which can be less straightforward.\n",
      "\n",
      "3. **Data Management**:\n",
      "   - **DevOps**: Data is typically static and well-defined, focusing on code and application deployment.\n",
      "   - **MLOps**: Data is dynamic and can change over time, requiring practices like data validation, data drift detection, and continuous data management to ensure model performance.\n",
      "\n",
      "4. **Experimentation and Iteration**:\n",
      "   - **DevOps**: Emphasizes continuous integration and continuous delivery (CI/CD) of software, where changes are made to code and deployed frequently.\n",
      "   - **MLOps**: Involves iterative experimentation with models, including data refinement, model selection, prompt engineering, and evaluation. The experimentation process is more complex due to the need to assess model performance and adapt based on results.\n",
      "\n",
      "5. **Monitoring and Evaluation**:\n",
      "   - **DevOps**: Focuses on application performance monitoring, uptime, and user experience.\n",
      "   - **MLOps**: Requires monitoring model performance, detecting model drift, and ensuring that the model continues to meet performance standards over time. Evaluation metrics can be more subjective and complex due to the nature of machine learning outputs.\n",
      "\n",
      "6. **Collaboration**:\n",
      "   - **DevOps**: Encourages collaboration between developers and operations teams.\n",
      "   - **MLOps**: Requires collaboration among data scientists, machine learning engineers, and operations teams, as well as potentially involving domain experts to ensure that models are aligned with business objectives.\n",
      "\n",
      "In summary, while both MLOps and DevOps aim to improve the efficiency and reliability of software delivery, MLOps introduces additional complexities related to data, model management, and the iterative nature of machine learning, necessitating specialized practices and tools.\n"
     ]
    }
   ],
   "source": [
    "# Input to the chain\n",
    "inputs = {\n",
    "    \"context\": llm_ops_content(),\n",
    "    \"question\": \"How is Mlops different from Devops?\"\n",
    "}\n",
    "\n",
    "# Run the chain\n",
    "response = chain.invoke(inputs)\n",
    "\n",
    "# Print the response\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-tutorial-yQKMQt2w-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
